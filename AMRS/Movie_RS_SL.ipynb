{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162cf66a-b87d-4d93-8631-65c9143542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "path = \"imdb_movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fcce85-54cb-47e1-a023-8c0d959afeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    unlabeled_data = data[data[\"genre\"].isna()]\n",
    "    labelled_data = data.drop(index= unlabeled_data.index)\n",
    "    return labelled_data,unlabeled_data\n",
    "labelled_data,unlabeled_data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff1f869-d6f8-42db-9e81-efe09814ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_preprocess(lst):\n",
    "    out = []\n",
    "    for i in lst:\n",
    "        i = i.lower()\n",
    "        i = i.replace(u'\\u00A0',u'')\n",
    "        out.append(i)\n",
    "    return out\n",
    "labelled_data[\"genre\"] = labelled_data[\"genre\"].str.split(\",\")\n",
    "labelled_data[\"genre\"] = labelled_data[\"genre\"].apply(label_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d96ca08-f8ee-41be-aa75-9e8f57903362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    x = re.sub(r\"[^\\w\\s]\",\" \",x)\n",
    "    x = x.lower()\n",
    "    words = word_tokenize(x)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lem = WordNetLemmatizer()\n",
    "    words = [lem.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)\n",
    "labelled_data[\"overview\"] = labelled_data[\"overview\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a145c1-bb33-4cb3-bb95-67b37a6c6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = labelled_data[\"overview\"]\n",
    "y = labelled_data[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17893c-c06a-4250-8334-7e129a0b1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_features=50000\n",
    ")\n",
    "\n",
    "x_transformed = tfid.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705af6a-36b4-4b10-8a1b-5ec6dc861ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_transformed,y,test_size=0.3,random_state=42)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5c17b-b351-4605-b03e-080be29ea58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.fit_transform(y_test)\n",
    "\n",
    "lr = LogisticRegression(C = 1,n_jobs=-1,max_iter=1000,class_weight=\"balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fdba7-a687-4d02-b4ec-acada7e37ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ovr = OneVsRestClassifier(lr)\n",
    "ovr.fit(x_train,y_train)\n",
    "y_pred = ovr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91dd3f-ca94-405c-b88b-ab5124de27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"Micro-F1:\", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99966f-65fc-402d-a974-972426b3f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd3d91-5cfc-4f83-bd41-29b9b8552c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = ovr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3dcfe-88ee-4339-9bb5-7b285c46eac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "for i, genre in enumerate(mlb.classes_):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test[:, i], y_proba[:, i])\n",
    "    best_threshold = thresholds[(precision * recall).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f9c35-7112-422a-831b-1b0303ba6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c8b7e-d890-44d0-ad10-1eb8131276dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# y_test: shape (n_samples, n_labels)    # multi-label binary matrix\n",
    "# y_proba: shape (n_samples, n_labels)   # per-label probabilities from predict_proba\n",
    "n_labels = y_test.shape[1]\n",
    "best_thresholds = np.empty(n_labels, dtype=float)\n",
    "\n",
    "for i in range(n_labels):\n",
    "    p, r, t = precision_recall_curve(y_test[:, i], y_proba[:, i])\n",
    "    # Compute F1 for each threshold-aligned point\n",
    "    f1 = 2 * p * r / (p + r + 1e-12)\n",
    "    # Align with thresholds: drop the last precision/recall point (no threshold for it)\n",
    "    f1 = f1[:-1]\n",
    "\n",
    "    if t.size == 0 or np.all(np.isnan(f1)):\n",
    "        # Fallback if no positive examples or degenerate curve\n",
    "        best_thresholds[i] = 0.5\n",
    "    else:\n",
    "        j = np.nanargmax(f1)\n",
    "        best_thresholds[i] = t[j]\n",
    "\n",
    "print(\"Per-class thresholds:\", best_thresholds)  # one threshold per genre\n",
    "\n",
    "# Apply thresholds (broadcasts across columns)\n",
    "y_pred = (y_proba >= best_thresholds).astype(int)\n",
    "\n",
    "# Re-evaluate\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(\"Micro-F1:\", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "# If you have mlb:\n",
    "# print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98a646-a406-4fe5-b2df-671fbe0a9c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
